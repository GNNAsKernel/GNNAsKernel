train:
  batch_size: 32
  lr_patience: 20
  epochs: 125
  # dropout: 0.3

model:
  hidden_size: 128
  num_layers: 4
  pool: add
  embs: (0, 1, 2)
  embs_combine_mode: 'concat'

subgraph:
  hops: 3
  # walk_length: 5
  # walk_p: 1.
  # walk_q: 1.
  # walk_repeat: 4